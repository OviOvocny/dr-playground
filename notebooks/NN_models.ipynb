{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#print type of GPU \n",
    "print(\"Using: \", torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid scaling done\n",
      "Data ready\n"
     ]
    }
   ],
   "source": [
    "# load parquet file \n",
    "phishing = pq.read_table('../data/floor/phishing.parquet')\n",
    "benign = pq.read_table('../data/floor/benign.parquet')\n",
    "\n",
    "from loader.transformers.cast_timestamp import cast_timestamp\n",
    "from loader.transformers.drop_nontrain import drop_nontrain\n",
    "\n",
    "phishing = drop_nontrain(phishing)\n",
    "benign = drop_nontrain(benign)\n",
    "\n",
    "# realign schemas (parquet files save in nonsense orders)\n",
    "benign = benign.cast(phishing.schema)\n",
    "\n",
    "# concatentate tables\n",
    "data = pa.concat_tables([phishing, benign])\n",
    "df = data.to_pandas()\n",
    "\n",
    "df = cast_timestamp(df)\n",
    "# create train and test sets\n",
    "    \n",
    "class_map = {\"benign:unknown\": 0, \"misp:phishing\": 1}\n",
    "\n",
    "labels = df['label'].apply(lambda x: class_map[x]) # y vector\n",
    "features = df.drop('label', axis=1).copy() # X matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "features,\n",
    "labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# fill nans with 0 in X_train and X_test and y_train and y_test\n",
    "    \n",
    "x_train = X_train.fillna(0)\n",
    "x_test = X_test.fillna(0)\n",
    "    \n",
    "y_train = y_train.fillna(0)\n",
    "y_test = y_test.fillna(0)\n",
    "    \n",
    "# convert x_train to numpy array\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "    \n",
    "y_test = y_test.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "    \n",
    "    # Converting False and True to 0 and 1\n",
    "x_train = np.where(x_train == False, 0, x_train)\n",
    "x_train = np.where(x_train == True, 1, x_train)\n",
    "    \n",
    "x_test = np.where(x_test == False, 0, x_test)\n",
    "x_test = np.where(x_test == True, 1, x_test)\n",
    "    \n",
    "\n",
    "    \n",
    " # transform all datapoints using sigmoid function\n",
    "    \n",
    "for item in x_test:\n",
    "    for i in range(len(item)):\n",
    "        item[i] = 1/(1+math.exp(-item[i]))\n",
    "            \n",
    "for item in x_train:\n",
    "    for i in range(len(item)):\n",
    "        item[i] = 1/(1+math.exp(-item[i]))\n",
    "            \n",
    "print(\"Sigmoid scaling done\")\n",
    "print(\"Data ready\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\t\t\n",
    "Class: Net\n",
    "pytorch definition of neural network structure\n",
    "\n",
    "'''       \n",
    "class Net(nn.Module):\n",
    "\n",
    "    # Network structure definition\n",
    "    def __init__(self):         \n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(81, 2500)\n",
    "        self.fc2 = nn.Linear(2500, 600)\n",
    "        self.fc3 = nn.Linear(600, 200)\n",
    "        self.fc4 = nn.Linear(200, 1)\n",
    "\n",
    "\n",
    "    # Data flow definition\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return torch.sigmoid(self.fc4(x)) # For binary classification is sigmoid best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN train and test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_train(x_train, y_train):\n",
    "    print(\"Training model...\")\n",
    "    counter = 1\n",
    "    sum = 0\n",
    "    batch_sum = 0\n",
    "\n",
    "\n",
    "    checkpoint_position = 8000\n",
    "    f1_checkpoint = 5000\n",
    "    \n",
    "    # calculation of f1 by hand my god...\n",
    "    tp_res = 0\n",
    "    tn_res = 0\n",
    "    \n",
    "    fp_res = 0\n",
    "    fn_res = 0\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(0, len(x_train)):\n",
    "        \n",
    "        # convert x_train[i] to list\n",
    "        input_data = torch.tensor(x_train[i].tolist(), device=device).float()\n",
    "        target_data = torch.tensor(y_train[i].tolist(), device=device).float()\n",
    "        \n",
    "        \n",
    "\n",
    "        # start real time timer\n",
    "        timer = time.time()\n",
    "        \n",
    "   #\n",
    "        \n",
    "        \n",
    "        # feed the data to the network\n",
    "        output=net(input_data)\n",
    "        \n",
    "        \n",
    "        if counter % checkpoint_position == 0:\n",
    "            time_per_cycle = (time.time() - timer)*1000/checkpoint_position\n",
    "            \n",
    "            \n",
    "            \n",
    "            # using counter, checkopint_position and checkopint_counter calculate time for one iteration is ms\n",
    "            # time per cycle in ms\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            if counter > f1_checkpoint + checkpoint_position:\n",
    "                #print(\"tp:\", tp_res, \"tn:\", tn_res, \"fp:\", fp_res, \"fn:\", fn_res)\n",
    "                try:\n",
    "                    precision = tp_res/(tp_res+fp_res)\n",
    "                    recall = tp_res/(tp_res+fn_res)\n",
    "                    \n",
    "                    #print(\"precision:\", round(precision, 3), \"recall:\", round(recall, 3))\n",
    "                    \n",
    "                    f1 = 2*((precision*recall)/(precision+recall))\n",
    "                    \n",
    "                    #print(\"F1:\", round(f1, 4), \"True positive:\", tp_res)\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "                    #print('Zero in denominator')\n",
    "                    #print(\"tp:\", tp_res, \"tn:\", tn_res, \"fp:\", fp_res, \"fn:\", fn_res)\n",
    "                    \n",
    "                    \n",
    "            precision = tp_res/(tp_res+fp_res)\n",
    "            recall = tp_res/(tp_res+fn_res)   \n",
    "            f1 = 2*((precision*recall)/(precision+recall))    \n",
    "            print(\"Loss:\", round(sum/checkpoint_position, 3), \"F1:\", round(f1, 4),\"Progress:\",  round((counter/len(x_train))*100, 3), \"%\", \"Time per cycle:\", round(time_per_cycle, 5), \"ms\")\n",
    "\n",
    "\n",
    "            sum=0\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "        # convert expected results to torch format\n",
    "\n",
    "        \n",
    "        \n",
    "        # increment tp, tn, fp, fn\n",
    "        if output >= 0.5 and target_data == 1:\n",
    "            tp_res+=1\n",
    "        elif output < 0.5 and target_data == 0:\n",
    "            tn_res+=1\n",
    "        elif output >= 0.5 and target_data == 0:\n",
    "            fp_res+=1\n",
    "        elif output < 0.5 and target_data == 1:\n",
    "            fn_res+=1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        loss = loss_fn(output, torch.FloatTensor([target_data]).to(device))\n",
    "        \n",
    "        sum+=float(loss)\n",
    "        batch_sum+=float(loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Batch loss:\", float(batch_sum)/float(len(x_train)))\n",
    "    print(\"--------------------------------------------------\")\n",
    "            \n",
    "\n",
    "def test(x_test, y_test):\n",
    "    \n",
    "    tp_res = 0\n",
    "    tn_res = 0\n",
    "    \n",
    "    fp_res = 0\n",
    "    fn_res = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Benchmarking model...\")\n",
    "    for i in range(0, len(x_test)):\n",
    "        #print(x_test[i].tolist())\n",
    "        \n",
    "        #print start of the progress bar    \n",
    "        print(\"Progress:\", round((i/len(x_test))*100, 3), \"%\", end=\"\\r\")\n",
    "\n",
    "        input_data = torch.tensor(x_test[i].tolist(), device=device).float()\n",
    "        target_data = torch.tensor(y_test[i].tolist(), device=device).float()\n",
    "        \n",
    "        \n",
    "        output=net(input_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if output >= 0.5 and target_data == 1:\n",
    "            tp_res+=1\n",
    "        elif output < 0.5 and target_data == 0:\n",
    "            tn_res+=1\n",
    "        elif output >= 0.5 and target_data == 0:\n",
    "            fp_res+=1\n",
    "        elif output < 0.5 and target_data == 1:\n",
    "            fn_res+=1\n",
    "    \n",
    "    #compute F1\n",
    "    recall = tp_res/(tp_res+fn_res)\n",
    "    precision = tp_res/(tp_res+fp_res)\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    \n",
    "    print(\"f1: \", f1)\n",
    "    \n",
    "    # Nicely print confusion matrix\n",
    "    data = {'Actual Positive': [tp_res, fn_res],\n",
    "        'Actual Negative': [fp_res, tn_res]}\n",
    "\n",
    "    df = pd.DataFrame(data, index = ['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters and setup\n",
    "\n",
    "- Loading pre-trained model from file \n",
    "- Network constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved_model = True\n",
    "save_after_batch = True\n",
    "model_path = \"./models/2500phish_net\"\n",
    "\n",
    "\n",
    "### Netowrk parameters ###\n",
    "learning_rate = 0.000001\n",
    "epoch_count = 25\n",
    "\n",
    "net = Net()\n",
    "\n",
    "if use_saved_model: \n",
    "    net = pickle.load(open(model_path, 'rb'))\n",
    "    \n",
    "\n",
    "# send model to GPU\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i in range(epoch_count):\n",
    "    nn_train(x_array, y_train)\n",
    "    print(\"Batch number:\", i)\n",
    "        \n",
    "    if save_after_batch:\n",
    "        # save model using pickle\n",
    "        print(\"Saving model after batch\")\n",
    "        pickle.dump(net, open(\"./models/2500phish_net\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking model...\n",
      "f1:  0.8276667353527029\n",
      "                    Actual Positive  Actual Negative\n",
      "Predicted Positive             6025             1136\n",
      "Predicted Negative             1373            50537\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb Cell 11\u001B[0m in \u001B[0;36m1\n\u001B[1;32m     <a href='vscode-notebook-cell:/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001B[0m test(x_test, y_test)\n\u001B[1;32m     <a href='vscode-notebook-cell:/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001B[0m exit(\u001B[39m0\u001B[39m)\n\u001B[0;32m---> <a href='vscode-notebook-cell:/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001B[0m optimizer \u001B[39m=\u001B[39m optim\u001B[39m.\u001B[39mAdam(net\u001B[39m.\u001B[39mparameters(), lr\u001B[39m=\u001B[39mlearning_rate)\n\u001B[1;32m     <a href='vscode-notebook-cell:/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001B[0m loss_fn \u001B[39m=\u001B[39m nn\u001B[39m.\u001B[39mBCELoss()\n\u001B[1;32m     <a href='vscode-notebook-cell:/home/poli/Desktop/git/dr-playground-old/NN_models.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001B[0m optimizer\u001B[39m.\u001B[39mzero_grad()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST NN\n",
    "test(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
